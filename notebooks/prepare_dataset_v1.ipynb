{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cuongld/anaconda3/envs/llm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('vinai/PhoGPT-7B5-Instruct', \n",
    "                                          trust_remote_code=True, \n",
    "                                          token='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',\n",
    "                                          cache_dir='./cache',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 2, 0, 3], ['<s>', '</s>', '<unk>', '<pad>'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.all_special_ids, tokenizer.all_special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[30689,  1819,  8303,  6298,  2001,  9251, 17084, 12888,  1819,  6177,\n",
       "          3339,    17,     2,    86,    33, 49742,  1120,  1819, 16974,  6919,\n",
       "         75299,    17]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'là một mặt hàng được đại diện bởi một thực thể.</s>Bạn là một trợ lý AI.' \n",
    "tokenizer(text, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<s>',\n",
       " 'eos_token': '</s>',\n",
       " 'unk_token': '<unk>',\n",
       " 'pad_token': '<pad>'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def format_prompt(sample):\n",
    "#     question, context, answer = sample['question'], sample['context'], sample['answer']\n",
    "\n",
    "#     if context != None and context != '':\n",
    "#         return f'### Câu hỏi:\\nDựa vào văn bản sau đây:\\n{context}\\nHãy trả lời câu hỏi: {question}\\n\\n### Trả lời:\\n{answer}'\n",
    "#     else:\n",
    "#         return f'### Câu hỏi:\\n{question}\\n\\n### Trả lời:\\n{answer}'\n",
    "\n",
    "def format_prompt(sample):\n",
    "    question, context = sample['question'], sample['context']\n",
    "    answer = sample['answer']\n",
    "    if sample['type'] == 'Instruction':\n",
    "        system = context + '\\n'\n",
    "        prompt = question\n",
    "        prompt = f'{system}### Câu hỏi:\\n{prompt}\\n\\n### Trả lời:\\n{answer}'\n",
    "    else:\n",
    "        if context is not None and context != '':\n",
    "            prompt = f'### Câu hỏi:\\nDựa vào văn bản sau đây:\\n{context}\\nHãy trả lời câu hỏi: {question}\\n\\n### Trả lời:\\n{answer}'\n",
    "        else:\n",
    "            prompt = f'### Câu hỏi:\\n{question}\\n\\n### Trả lời:\\n{answer}'\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def template_data(sample):\n",
    "    # sample['text'] = tokenizer.bos_token + format_prompt(sample) + tokenizer.eos_token\n",
    "    sample['text'] = format_prompt(sample) + tokenizer.eos_token\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from functools import partial\n",
    "# empty list to save remainder from batches to use in next batch\n",
    "remainder = {\"input_ids\": [], \"attention_mask\": [], \"token_type_ids\": []}\n",
    "\n",
    "def chunk(sample, chunk_length=4096):\n",
    "    # define global remainder variable to save remainder from batches to use in next batch\n",
    "    global remainder\n",
    "    # Concatenate all texts and add remainder from previous batch\n",
    "    concatenated_examples = {k: list(chain(*sample[k])) for k in sample.keys()}\n",
    "    concatenated_examples = {k: remainder[k] + concatenated_examples[k] for k in concatenated_examples.keys()}\n",
    "    # get total number of tokens for batch\n",
    "    batch_total_length = len(concatenated_examples[list(sample.keys())[0]])\n",
    "\n",
    "    # get max number of chunks for batch\n",
    "    if batch_total_length >= chunk_length:\n",
    "        batch_chunk_length = (batch_total_length // chunk_length) * chunk_length\n",
    "\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + chunk_length] for i in range(0, batch_chunk_length, chunk_length)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    # add remainder to global variable for next batch\n",
    "    remainder = {k: concatenated_examples[k][batch_chunk_length:] for k in concatenated_examples.keys()}\n",
    "    # prepare labels\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tuannd/.local/lib/python3.10/site-packages/pyarrow/pandas_compat.py:373: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if _pandas_api.is_sparse(col):\n"
     ]
    }
   ],
   "source": [
    "data_train = pd.read_csv('/home4/tuannd/llm-training/Data_Vi_QA_v1.1/all_data.csv')\n",
    "data_train = data_train.fillna('')\n",
    "dataset = Dataset.from_pandas(data_train[['question', 'answer', 'context', 'type']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "Abstractive            131985\n",
       "Conversation_1_turn    110781\n",
       "Instruction             68619\n",
       "no answer               20053\n",
       "Extractive              18579\n",
       "QA_Uni                  12493\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# # set seed\n",
    "# import random\n",
    "# random.seed(42)\n",
    "# data_train = data_train[data_train['type'] != 'chat']\n",
    "# data_train = data_train[data_train['type'] != 'nocontext']\n",
    "\n",
    "# train_dataset, test_dataset = train_test_split(data_train, test_size=0.25, stratify=data_train['type'])\n",
    "# print(test_dataset['type'].value_counts())\n",
    "# len(train_dataset), len(test_dataset)\n",
    "# test_dataset = Dataset.from_pandas(test_dataset[['question', 'answer', 'context', 'type']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Format data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 362510/362510 [00:32<00:00, 11168.45 examples/s]\n"
     ]
    }
   ],
   "source": [
    "print('Format data ...')\n",
    "lm_dataset = dataset.map(template_data, remove_columns=['question', 'answer', 'context'])\n",
    "# tokenize and chunk dataset\n",
    "\n",
    "# print('Tokenize data ...')\n",
    "# lm_dataset = lm_dataset.map(\n",
    "#     lambda sample: tokenizer(sample[\"text\"]), batched=True\n",
    "# )\n",
    "\n",
    "# lm_dataset = lm_dataset.remove_columns(\"text\")\n",
    "\n",
    "# print('Chunk data ...')\n",
    "# CHUNK_SIZE = 2048\n",
    "# train_dataset = lm_dataset.map(\n",
    "#     partial(chunk, chunk_length=CHUNK_SIZE),\n",
    "#     batched=True,\n",
    "# )\n",
    "\n",
    "# # Print total number of samples\n",
    "# print(f\"Total number of samples: {len(train_dataset)}\")\n",
    "\n",
    "# Total number of samples: 293686"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 362510/362510 [00:04<00:00, 86578.93 examples/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Câu hỏi:\n",
      "Giới tính của bạn là gì?\n",
      "\n",
      "### Trả lời:\n",
      "Tôi không có giới tính vì tôi chỉ là một chương trình máy tính, không có bản dạng vật lý hoặc tồn tại trong thế giới thực. Tôi được thiết kế để hỗ trợ bạn bằng cách cung cấp thông tin và trợ giúp trong việc trả lời câu hỏi liên quan đến quy định, quy chế và đào tạo của Đại học Bách Khoa Hà Nội. Tôi sẵn sàng giúp đỡ nếu bạn có những thắc mắc liên quan đến HUST!</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "print(lm_dataset.filter(lambda x: x['type'] == 'QA_Uni')[5]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenize data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   4%|▍         | 14000/362510 [00:02<01:26, 4033.23 examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (2401 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Map: 100%|██████████| 362510/362510 [01:52<00:00, 3228.03 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 362510/362510 [02:32<00:00, 2377.41 examples/s]\n"
     ]
    }
   ],
   "source": [
    "print('Tokenize data ...')\n",
    "\n",
    "lm_tkn_dataset = lm_dataset.map(\n",
    "    lambda sample: tokenizer(sample[\"text\"]), batched=True\n",
    ")\n",
    "\n",
    "print('Chunk data ...')\n",
    "lm_tkn_dataset = lm_tkn_dataset.remove_columns(\"text\")\n",
    "lm_tkn_dataset = lm_tkn_dataset.remove_columns(\"type\")\n",
    "\n",
    "CHUNK_SIZE = 2048\n",
    "final_dataset = lm_tkn_dataset.map(\n",
    "    partial(chunk, chunk_length=CHUNK_SIZE),\n",
    "    batched=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63537"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 63537/63537 [02:26<00:00, 435.08 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "63537"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final_dataset = final_dataset.filter(lambda x: len(x['input_ids']) <= 2048)\n",
    "# len(final_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (4/4 shards): 100%|██████████| 63537/63537 [00:17<00:00, 3618.56 examples/s] \n"
     ]
    }
   ],
   "source": [
    "final_dataset.save_to_disk('train_final_pack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iv) con người (v) số (vi) vị trí Câu trả lời cho câu hỏi\" Thức uống nào chứa càng nhiều loại rượu rum càng tốt?\" là một thực thể, một từ viết tắt, một mô tả, một con người, một địa điểm hay một giá trị số?\n",
      "\n",
      "\n",
      "\n",
      "### Trả lời:\n",
      "Để xác định danh mục cho câu trả lời cho câu hỏi\" Thức uống nào chứa càng nhiều loại rượu rum càng tốt?\" , hãy phân tích từng lựa chọn có sẵn một:\n",
      "\n",
      " (i) Mô tả: Có thể câu trả lời có thể bao gồm một mô tả, nhưng đây không phải là kết quả có nhiều khả năng xảy ra nhất. Một mô tả sẽ trình bày một lời giải thích về thức uống hơn là tên của thức uống.\n",
      "\n",
      " (ii) Thực thể: Câu trả lời cho câu hỏi này rất có thể là một thực thể, vì tên của thức uống đại diện cho một mặt hàng cụ thể.\n",
      "\n",
      " (iii) Viết tắt: Tùy chọn này cũng có thể xảy ra, nhưng ít khả năng xảy ra hơn so với lựa chọn thực thể. Câu trả lời có khả năng là tên viết tắt của tên đồ uống, nhưng nhiều khả năng nó là tên đầy đủ của đồ uống—một thực thể.\n",
      "\n",
      " (iv) Con người: Câu trả lời sẽ không phải là con người, vì câu hỏi hỏi về đồ uống chứ không phải một cá nhân.\n",
      "\n",
      " (v) Số: Câu trả lời sẽ không phải là giá trị số, vì câu hỏi yêu cầu tên của đồ uống, sẽ không được biểu thị bằng số.\n",
      "\n",
      " (vi) Vị trí: Câu trả lời sẽ không phải là vị trí, vì câu hỏi đang hỏi về đồ uống chứ không phải vị trí địa lý.\n",
      "\n",
      " Bằng cách phân tích từng lựa chọn, câu trả lời cho câu hỏi\" Thức uống nào chứa càng nhiều loại rượu rum càng tốt?\" rất có thể sẽ được phân loại là một\" thực thể.\" Điều này là do câu trả lời được mong đợi là tên của một loại đồ uống cụ thể, là một mặt hàng được đại diện bởi một thực thể.</s>Bạn là một trợ lý AI. Người dùng sẽ cung cấp cho bạn một nhiệm vụ. Mục tiêu của bạn là hoàn thành nhiệm vụ một cách trung thực nhất có thể. Trong khi thực hiện nhiệm vụ, hãy suy nghĩ từng bước một và biện minh cho các bước của bạn.\n",
      "### Câu hỏi:\n",
      "Điều gì xảy ra tiếp theo trong đoạn này?\n",
      "\n",
      " Có một người đàn ông đội mũ đỏ và mặc áo sơ mi đen đang huấn luyện và chơi với chú chó của mình trong công viên dành cho chó. Có một số người khác trong công viên đó với những con chó của họ, ngồi dưới tán cây. người đàn ông\n",
      " Các tùy chọn là: a). sau đó đứng trước mặt con chó đang chơi và huấn luyện nó và bắt đầu dạy nó karate.; b). mặc một chiếc áo sơ mi đen và quần đùi đen, vừa chạy bộ vừa đi theo một con chó nhỏ.; c). đang nói về trò chơi hiện đang ngồi trong một chuồng lớn trong nhà trong khi chú chó này đang học cách chơi cùng nhau.; đ). đang ném một chiếc đĩa nhựa để con chó lấy.;\n",
      "\n",
      "### Trả lời:\n",
      "đ). đang ném một chiếc dĩa nhựa cho con chó để lấy.\n",
      "\n",
      " Lập luận từng bước:\n",
      "\n",
      " 1. Đoạn văn miêu tả một người đàn ông chơi với con chó của mình tại công viên dành cho chó. Điều này gợi ý rằng hành động tiếp theo sẽ liên quan đến việc người đàn ông lôi kéo con chó của mình vào một hoạt động.\n",
      "\n",
      " 2. Tùy chọn a) giới thiệu karate, đây không phải là hoạt động điển hình hoặc có liên quan để thực hiện với chó tại công viên dành cho chó, vì vậy đây không phải là phần tiếp theo tốt nhất.\n",
      "\n",
      " 3. Lựa chọn b) lặp lại mô tả quần áo của người đàn ông, điều này không tiến triển câu chuyện và cũng có vẻ không liên quan. Việc đề cập đến chạy bộ là một hoạt động khả thi, nhưng nó không liên quan trực tiếp đến khía cạnh huấn luyện chó.\n",
      "\n",
      " 4. Lựa chọn c) gợi ý thay đổi sang ngồi trong khu vực kín trong nhà khi trò chuyện về trò chơi, đây là một sự thay đổi đáng kể so với bối cảnh công viên dành cho chó ngoài trời và có vẻ không phù hợp lắm với kịch bản.\n",
      "\n",
      " 5. Lựa chọn d) liên quan đến việc người đàn ông ném đĩa nhựa cho con chó của mình, một hoạt động phổ biến trong công viên dành cho chó và có liên quan đến bối cảnh chơi và huấn luyện chó trong khung cảnh ngoài trời.</s>Bạn là một trợ lý AI. Bạn sẽ được giao một nhiệm vụ. Bạn phải tạo ra một câu trả lời chi tiết và dài.\n",
      "### Câu hỏi:\n",
      "Dưới đây là một số từ khóa về một nhà hàng:\n",
      "\n",
      " tên = The Waterman, đồ ăn = tiếng Trung Quốc, giáPhạm vi = vừa phải, đánh giá của khách hàng = 3 trên 5, khu vực = trung tâm thành phố, Thân thiện với gia đình = không. Viết một câu mô tả các thuộc tính sau của một nhà hàng.\n",
      "\n",
      "### Trả lời:\n",
      "Waterman, nằm ở trung tâm thành phố nhộn nhịp, cung cấp nhiều món ăn Trung Hoa thú vị với giá cả phải chăng; tuy nhiên, với đánh giá khiêm tốn của khách hàng là 3 trên 5 sao, đây có thể không phải là lựa chọn lý tưởng cho trải nghiệm ăn uống thân thiện với gia đình.</s>Bạn là một trợ lý AI. Người dùng sẽ cung cấp cho bạn một nhiệm vụ. Mục tiêu của bạn là hoàn thành nhiệm vụ một cách trung thực nhất có thể. Trong khi thực hiện nhiệm vụ, hãy suy nghĩ từng bước một và biện minh cho các bước của bạn.\n",
      "### Câu hỏi:\n",
      "Viết một bài báo dựa trên bản tóm tắt này:\n",
      "\n",
      " Mở WhatsApp. Nhấn vào biểu tượng trò chuyện mới. Nhấn vào biểu tượng liên hệ mới. Chọn một vị trí lưu trữ. Nhập tên cho số liên lạc. Nhập số điện thoại quốc tế của số liên lạc. Nhấn Xong. Nhấn vào nút quay lại cho đến khi bạn quay lại cuộc trò chuyện mới. Vỗ nhẹ ⁝. Nhấn Làm mới.\n",
      "\n",
      " Bài báo:\n",
      "\n",
      "### Trả lời:\n",
      "Tiêu đề: Cách thêm và làm mới liên hệ mới trên WhatsApp\n",
      "\n",
      " Giới thiệu\n",
      "\n",
      " WhatsApp là một ứng dụng nhắn tin phổ biến được hàng triệu người trên thế giới sử dụng. Một trong những tính năng thiết yếu của WhatsApp là thêm liên hệ vào danh sách của bạn, cho phép bạn liên lạc với bạn bè, gia đình và đồng nghiệp. Hướng dẫn này sẽ hướng dẫn bạn quy trình thêm và làm mới một liên hệ mới trên ứng dụng.\n",
      "\n",
      " Bước 1: Mở WhatsApp\n",
      "\n",
      " Đầu tiên, hãy mở ứng dụng WhatsApp trên điện thoại thông minh hoặc thiết bị của bạn. Đảm bảo bạn có kết nối internet đang hoạt động, vì điều này là cần thiết để gửi và nhận tin nhắn, cũng như thêm địa chỉ liên hệ.\n",
      "\n",
      " Bước 2: Truy cập Trò chuyện mới\n",
      "\n",
      " Sau khi WhatsApp mở, hãy tìm biểu tượng trò chuyện mới, thường được biểu thị dưới dạng bong bóng trò chuyện với một\" +\" hoặc biểu tượng bút chì. Biểu tượng này thường xuất hiện ở đầu hoặc cuối màn hình, tùy thuộc vào thiết bị của bạn. Nhấn vào biểu tượng trò chuyện mới để chuyển sang bước tiếp theo.\n",
      "\n",
      " Bước 3: Nhấn vào Biểu tượng Liên hệ Mới\n",
      "\n",
      " Trong menu trò chuyện mới, bạn sẽ tìm thấy biểu tượng liên hệ mới. Biểu tượng này thường là một người có\" +\" biểu tượng hoặc đơn giản\" +\" biểu tượng. Nhấn vào biểu tượng liên hệ mới để truy cập các tùy chọn tạo liên hệ.\n",
      "\n",
      " Bước 4: Chọn vị trí lưu trữ\n",
      "\n",
      " Bây giờ, bạn sẽ cần chọn một vị trí lưu trữ cho liên hệ mới của mình. Đây có thể là bộ nhớ trong của thiết bị hoặc nguồn bên ngoài, chẳng hạn như tài khoản Google được liên kết. Chọn vị trí mong muốn và tiến hành bước tiếp theo.\n",
      "\n",
      " Bước 5: Thêm tên liên hệ\n",
      "\n",
      " Trong menu tạo liên hệ, hãy nhập tên của liên hệ mới vào trường được chỉ định. Tên này sẽ giúp bạn dễ dàng xác định số liên lạc trong các cuộc hội thoại sau này.\n",
      "\n",
      " Bước 6: Thêm số điện thoại quốc tế\n",
      "\n",
      " Sau tên, nhập số điện thoại quốc tế của liên hệ, bao gồm cả mã quốc gia. Đảm bảo nhập số chính xác để có thể liên lạc qua nền tảng.\n",
      "\n",
      " Bước 7: Lưu Liên hệ Mới\n",
      "\n",
      " Khi bạn đã thêm tên và số điện thoại của liên hệ, hãy nhấn vào\" Xong\" hoặc nút đánh dấu để lưu số liên lạc. Liên hệ mới bây giờ sẽ được thêm vào danh sách của bạn.\n",
      "\n",
      " Bước 8: Quay lại Menu trò chuyện mới\n",
      "\n",
      " Sau khi lưu liên hệ, hãy nhấn vào nút quay lại trên thiết bị của bạn cho đến khi bạn quay lại menu trò chuyện mới.\n",
      "\n",
      " Bước 9: Làm mới Danh sách Liên hệ\n",
      "\n",
      " Trong menu trò chuyện mới, hãy tìm biểu tượng menu (thường được biểu thị bằng ba dấu chấm dọc) và nhấn vào biểu tượng đó. Từ trình đơn thả xuống, chọn\" Làm cho khỏe lại.\" Hành động này sẽ cập nhật danh sách liên hệ của bạn, làm cho liên hệ mới được thêm vào hiển thị.\n",
      "\n",
      " Phần kết luận\n",
      "\n",
      " Với các bước đơn giản này, bạn có thể thêm và làm mới danh bạ mới trên WhatsApp một cách hiệu quả, đảm bảo rằng tất cả bạn bè và người quen của bạn đều sẵn sàng liên lạc liền mạch. Giờ đây, bạn có thể tiếp tục và tận hưởng việc chia sẻ tin nhắn, ảnh và tệp với liên hệ mới được thêm của mình trên nền tảng nhắn tin phổ biến này. Chúc bạn trò chuyện vui vẻ!</s>Bạn nên mô tả nhiệm vụ và giải thích câu trả lời của bạn. Trong khi trả lời câu hỏi trắc nghiệm, trước tiên hãy xuất (các) câu trả lời đúng. Sau đó giải thích tại sao các\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "ds = load_from_disk('train_final_pack')\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"aisingapore/sealion7b-instruct-nc\", \n",
    "#                                           trust_remote_code=True, \n",
    "#                                           token='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',)\n",
    "import random\n",
    "print(tokenizer.decode(ds[random.randint(0, len(ds)-1)]['input_ids']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
